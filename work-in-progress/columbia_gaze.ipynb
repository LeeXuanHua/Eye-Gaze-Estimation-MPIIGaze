{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from UnsupervisedGaze_model import *\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from progress.bar import Bar\n",
    "import sys\n",
    "import random\n",
    "\n",
    "def progressbar(it, prefix=\"\", size=60, out=sys.stdout):\n",
    "    count = len(it)\n",
    "    def show(j):\n",
    "        x = int(size*j/count)\n",
    "        print(\"{}[{}{}] {}/{}\".format(prefix, \"#\"*x, \".\"*(size-x), j, count), \n",
    "                end='\\r', file=out, flush=True)\n",
    "    show(0)\n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        show(i+1)\n",
    "    print(\"\\n\", flush=True, file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "\n",
    "randseed = 0.4 * np.random.rand(6) + 0.3\n",
    "\n",
    "preprocess_augmentation = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224, 224), scale=(0.5, 1.0), ratio=(0.95, 1.05)),\n",
    "    transforms.Normalize(mean=randseed[:3], std=randseed[3:]),\n",
    "])\n",
    "\n",
    "class Data_loader():\n",
    "    def __init__(self, path, train_test_ratio = 0.7, augmentation = True, plot_sample=False):\n",
    "        self.dirs = []\n",
    "        self.files_path = []\n",
    "        self.count = []\n",
    "        self.path = path\n",
    "        for each in os.listdir(path):\n",
    "            self.count.append(0)\n",
    "            if each[:2] == '00':\n",
    "                self.dirs.append(each)\n",
    "                self.files_path.append([f.path for f in os.scandir(path+each+'/') if f.is_file() and f.path[-9:]=='H_new.jpg'])\n",
    "                self.count[-1] += 1\n",
    "        self.split_index = round(train_test_ratio * len(self.files_path))\n",
    "        print(f\"[Data_loader] training set: {self.split_index} person |\")\n",
    "        print(f\"[Data_loader] test set: {len(self.files_path) - self.split_index} person |\")\n",
    "        self.images_train = []\n",
    "        self.gts_train = []\n",
    "        self.images_test = []\n",
    "        self.gts_test = []\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def read_angles(self, name):\n",
    "        filter = name.split(\"/\")[-1].split(\"_\")[3:]\n",
    "        yaw = int(filter[0][:-1])\n",
    "        pitch = int(filter[1].replace(\"H\", ''))\n",
    "        return yaw, pitch\n",
    "\n",
    "    def read_data(self, person, mode=\"TRAIN\"):\n",
    "        temp = []\n",
    "        ang = []\n",
    "        for file_name in person:\n",
    "            yaw, pitch = self.read_angles(file_name)\n",
    "            with Image.open(file_name) as image:\n",
    "              image_matrix = preprocess(image)\n",
    "            if self.augmentation and mode==\"TRAIN\" and np.random.randint(0,100) > 63:\n",
    "                image_matrix_augmentation = preprocess_augmentation(image_matrix)\n",
    "                temp.append(image_matrix_augmentation)\n",
    "                ang.append([yaw, pitch])\n",
    "            temp.append(image_matrix)\n",
    "            ang.append([yaw, pitch])\n",
    "        if mode == \"TRAIN\":\n",
    "            self.images_train.extend(temp)\n",
    "            self.gts_train.extend(ang)\n",
    "        else:\n",
    "            self.images_test.extend(temp)\n",
    "            self.gts_test.extend(ang)\n",
    "\n",
    "    def get_data(self):\n",
    "        for i, person in enumerate(self.files_path):\n",
    "            if i >= self.split_index:\n",
    "                self.read_data(person, mode=\"TEST\")\n",
    "            self.read_data(person)\n",
    "        return self.images_train, self.gts_train, self.images_test, self.gts_test\n",
    "\n",
    "ColumbiaGazeDataset = Data_loader(path = \"/root/Columbia Gaze Data Set/\")\n",
    "images_train, gts_train, images_test, gts_test = ColumbiaGazeDataset.get_data()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on : \", device)\n",
    "print(f\"Number of training images : {len(images_train)} test: {len(images_test)}\")\n",
    "\n",
    "images_train, images_test = torch.stack(images_train).to(device), torch.stack(images_test).to(device)\n",
    "gts_train, gts_test = torch.tensor(gts_train).to(device), torch.tensor(gts_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_abs_angle_difference(a, b):\n",
    "    cos_theta = torch.cos(a/180 * math.pi) * torch.cos(b/180 * math.pi) \n",
    "    theta = torch.acos(cos_theta)\n",
    "    return torch.abs(theta * 180 / math.pi)\n",
    "\n",
    "def test_baseline(data, number_of_epoch = 250, lr=1e-5, weight_decay=1e-3, batch_size = 16, show_images=False):\n",
    "    images = data[0]\n",
    "    gts = data[1]\n",
    "    images_test = data[2]\n",
    "    gts_test = data[3]\n",
    "    loss_hist = []\n",
    "    if show_images:\n",
    "        for _ in range(2):\n",
    "            num = np.random.randint(0, len(images))\n",
    "            plt.imshow(images[num, 0, :, :])\n",
    "            plt.title(f\"{gts[num]}\")\n",
    "            plt.show()\n",
    "    model = GazeRepresentationLearning_fullface()\n",
    "    model = model.to(device)\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    for epoch in range(number_of_epoch):\n",
    "        prev_time = time.time()\n",
    "        loss_hist.append([])\n",
    "        for i in range(3840//batch_size):\n",
    "            image_1 = images[batch_size*i:batch_size*(i+1)].view(batch_size, 3, images.size(-2), images.size(-1))\n",
    "            outputs = model(image_1)\n",
    "            gt = gts[batch_size*i:batch_size*(i+1)]\n",
    "            if epoch % 50 == 25 and i==0:\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] /= 4\n",
    "                print(\"reduce lr\")\n",
    "            loss = criterion(outputs, gts[batch_size*i:batch_size*(i+1)])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_hist[-1].append(float(loss))\n",
    "        if epoch%20 == 0:\n",
    "            print(f'epoch: {epoch+1} / {number_of_epoch}, loss: {sum(loss_hist[-1])/len(loss_hist[-1])}, time: {time.time() - prev_time} s')\n",
    "        torch.save(model, f\"/root/_KD/UnsupervisedBaseline_log_5/full_log/baseline_mixup_epoch={epoch}_loss={float(loss)}_{batch_size=}_{weight_decay=}.pt\")\n",
    "    outputs = model(images_test)\n",
    "    dif = gts_test - outputs\n",
    "    yaw = dif[:, 0]\n",
    "    pitch = dif[:, 1]\n",
    "    val = find_abs_angle_difference(yaw, pitch)\n",
    "    error = torch.sum(val/outputs.size(0))\n",
    "    print(f\": got mean angle error: {error}\")\n",
    "    torch.save(model, f\"/root/_KD/UnsupervisedBaseline_log_5/_final_baseline_mixup_error={float(error)}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f760b9e6be9c83b1915cbbde8c157c3697c3b1064baafa6b1fc68b577c71cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
